\section{Experimental Evaluation}
\label{sec:exp}

{\bf Experimental environment.} All experiments in this section were
conducted on a 16-slave in-house Open Stack cloud, using Linux Ubuntu
14.04 and Spark v2.0.  Each node has 4 cores and 16 GB of RAM.  Spark
Standalone cluster manager and Hadoop 2.6 were used.

Because Spark is a lazy evaluation system, a materialize operation was
appended to the end of each query, which consisted of the count of
nodes and edges.  Each experiment was conducted 3 times with a cold
start, we report the average running time, which is representative
because we took great care to control variability.  Standard deviation
for each measure is at or below 5\% of the mean except in cases of
very small running times.

\begin{table}
\caption{Experimental datasets.}
\small
\begin{tabular}{l | c | c | c | c }
\hline
\multicolumn{1}{l|}{\bfseries Dataset} & \multicolumn{1}{c|}{\bfseries |V|} & \multicolumn{1}{c|}{\bfseries |E|} & \multicolumn{1}{c|}{\bfseries Time Span} & \multicolumn{1}{c}{\bfseries Evol. Rate} \\ \hline
wikitalk-en & 2.9M & 10.7M & 2002--2015 & 14.4 \\ \hline
nGrams & 29.3M & 2.5B & 1520--2008 & 16.67 \\ \hline
%%DELIS & 128M & 40.5B & 2006--2007 & ? \\ \hline
twitter & 505.4M & 23B & 2006--2012 & ? \\ \hline
\end{tabular}
\label{tab:datasets}
\end{table}

{\bf Data.}  We evaluate performance of our framework on three real
open-source datasets: wikitalk, nGrams, and Twitter
(Table~\ref{tab:datasets}).  wikitalk~\cite{wikitalk} contains over 10
million messaging events among 3 million wiki-en users from 2002
through 2015, aggregated at 1 month resolution.  nGrams~\cite{nGrams}
contains word co-occurrence information from 1520 through 2008, with
30 million word nodes and over 2.5 billion undirected co-occurrence
edges.  twitter~\cite{twitter} contains over 23 billion directed
follower relationships between 0.5 billion twitter users collected in
2012, sampled at 1-month resolution based on account creation
information from April of 2006. \eat{DELIS contains monthly snapshots
  of a portion of the Web graph focusing on the .uk domains from
  05/2006 through 05/2007~\cite{BSVLTAG}. } The datasets differ not
only in size, but also in the number and type of attributes and the
rate of evolution.  The change rate was calculated as the average
graph edit similarity~\cite{Ren2011}.  \eat{the evolutionary
  properties: co-authorship network nodes and edges have limited
  lifespan, while the nGrams network grows over time, with nodes and
  edges persisting for long duration.  All figures in the body of this
  section are on the larger nGrams dataset.  Refer to the Appendix for
  the DBLP figures, which show similar trends as nGrams.}

The behavior of the four physical representations reported below is
dependent on the underlying data format on disk, described in the
previous section. and should be interpreted in that context.

\begin{figure*}
\centering
\begin{minipage}{2.2in}
\centering
\includegraphics[width=2.2in]{figs/slice_ngrams_vertices_build11_trimmed.png}
\vspace{-0.1in}
\caption{Slice on nGrams dataset, return vertices.}
\label{fig:sliceverts}
\vspace{-0.1in}
\end{minipage}
\begin{minipage}{2.2in}
\centering
\includegraphics[width=2.2in]{figs/slice_wikitalk_edges_build11_trimmed.png}
\vspace{-0.1in}
\caption{Slice on wikitalk dataset, return edges.}
\label{fig:sliceedges}
\vspace{-0.1in}
\end{minipage}
\begin{minipage}{2.2in}
\centering
\includegraphics[width=2.6in]{figs/project_wikitalk_vertices_build12.png}
\vspace{-0.1in}
\caption{Map on wikitalk dataset vertices.}
\label{fig:project}
\vspace{-0.1in}
\end{minipage}
\end{figure*}

{\bf Slice.}  \insql{slice} performance was evaluated by varying the
slice time window and materializing vertices or edges.  Recollect that
in \ve \insql{slice} is a simple select on the vertex and edge
relations and is the fastest access method when data on disk is
coalesced.  \sg, in contrast, does multiple passes of select over the
same data to compute each RG, and then coalesce the output to return a
valid result.  Thus, as expected, \ve behavior is directly dependent
on the size of input data regardless of the slice size for file
formats and systems without filter pushdown, as is the case here, or
if the data does not have temporal locality
(Figure~\ref{fig:sliceverts} - about 28 seconds for \ve,
Figure~\ref{fig:sliceedges}).  \sg behavior is linear in the slice
size.  This experiment essentially measures the cost of materializing
\sg from \ve.  However, we observed the same linear trend previously
when the data is stored as individual
snapshots~\cite{PortalarXiv2016}, although less redundant work is
needed in that case.

\begin{figure*}
\centering
\begin{minipage}{3.3in}
\centering
\includegraphics[width=2.8in]{figs/select_wikitalk_vertices_build12.png}
\caption{Select on the wikitalk dataset, return vertices.}
\vspace{-0.1in}
\label{fig:selectv}
\vspace{-0.1in}
\end{minipage}
\begin{minipage}{3.3in}
\centering
\includegraphics[width=2.8in]{figs/select_ngrams_edges_build12.png}
\vspace{-0.1in}
\caption{Select on the nGrams dataset, return edges.}
\vspace{-0.1in}
\label{fig:selecte}
\end{minipage}
\end{figure*}

{\bf Subgraph.}  \insql{subgraph} performance was evaluated by varying
selectivity over length of the vertex attribute.  When materializing
vertices, regardless of the evolution rate \ve provides better
performance than \sg and linear to selectivity.  Performance of \sg is
a function of the number of intervals and is insensitive to
the selectivity.  The behavior of \ve for edges
(Figure~\ref{fig:selecte}) is dominated by the foreign key constraint
enforcement: with small selectivity broadcast join affords performance
linear to the number of edges.  For large number of vertices broadcast
join is not feasible and a hash-join is used instead, which is
substantially slower.  Even then \ve provides an order of magnitude
better performance than \sg.

\eat{
\begin{figure}
\centering
\includegraphics[width=2.8in]{figs/project_wikitalk_vertices_build12.png}
\caption{Map vertex attribute into its length on the wikitalk dataset.}
\label{fig:project}
\end{figure}
}
{\bf Map.}  We evaluate \insql{map} performance by varying the
data size through the slice operation.  Similar to \insql{slice},
\insql{map} exhibits flat runtime for \ve and linear increase in
runtime with the number of RGs for \sg.  However, performance for \ve
is worse than performance on \insql{slice} because \insql{map}
requires a coalescing operation as the last step, while \insql{slice}
does not.

\begin{figure*}[h]
\begin{minipage}{2in}
\centering
\includegraphics[height=1.7in]{figs/agg_allall_wikitalk_vertices_build11_trimmed.png}
\caption{Aggregate by time, all/all quantification on the wikitalk dataset.}
\label{fig:agg1}
\end{minipage}
\begin{minipage}{2in}
\centering
\includegraphics[height=1.7in]{figs/agg_allall_ngrams_edges_build11_trimmed.png}
\caption{Aggregate by time, all/all quantification on the nGrams dataset.}
\label{fig:agg2}
\end{minipage}
\begin{minipage}{2.6in}
\centering
\includegraphics[height=1.7in]{figs/agg_allexists_wikitalk_edges_build11.png}
\caption{Aggregate by time, all/exists quantification on the wikitalk dataset.}
\label{fig:agg4}
\end{minipage}
\end{figure*}

\eat{
\begin{figure*}
\centering
\begin{minipage}{3.2in}
\centering
\includegraphics[width=3in]{figs/agg_allexists_ngrams_vertices_build11.png}
\vspace{-0.1in}
\caption{Aggregate by time, all/exists quantification on the nGrams dataset.}
\label{fig:agg3}
\vspace{-0.1in}
\end{minipage}
\begin{minipage}{3.2in}
\centering
\includegraphics[width=3in]{figs/agg_allexists_wikitalk_edges_build11.png}
\vspace{-0.1in}
\caption{Aggregate by time, all/exists quantification on the wikitalk dataset.}
\label{fig:agg4}
\vspace{-0.1in}
\end{minipage}
\end{figure*}
}
{\bf Aggregate.}  We evaluate the performance of structure-only
aggregation on all 4 representations by varying the aggregation
window.  \insql{aggregate} performance, whether by time or change,
depends heavily on the quantification and on the data evolution rate.
\og is an aggregated data structure with good temporal locality and
thus in most cases provides good performance insensitive to the
aggregation window size, e.g. Figure~\ref{fig:agg1}.  However, in
datasets with a large number of RGs (such as nGrams which has over 400
periods), \og exhibits slow performance, an order of magnitude worse
than \ve, except when materializing edges on small aggregation windows
(Figure~\ref{fig:agg2}).  \ve outperforms \og when the V and E
quantification levels match (Figure~\ref{fig:agg2}), but is worse than
\og when the foreign key constraint is manually enforced, which
happens with different levels of quantification for V and E
(Figure~\ref{fig:agg4}).  \ve also underperforms \og
when the evolution rate and the aggregation window are both small,
such as with the wikitalk dataset - Figure~\ref{fig:agg1}.  \sg and
\hg do not provide the best performance on any of our datasets.

\begin{figure*}[h]
\begin{minipage}{2.2in}
\centering
\includegraphics[width=2in]{figs/union_wikitalk_vertices_build12.png}
\caption{Union on the wikitalk dataset, return vertices.}
\label{fig:union1}
\end{minipage}
\begin{minipage}{2.2in}
\centering
\includegraphics[width=2in]{figs/union_wikitalk_edges_build12.png}
\caption{Union on the wikitalk dataset, return edges.}
\label{fig:union2}
\end{minipage}
\begin{minipage}{2.2in}
\centering
\includegraphics[width=2in]{figs/intersect_ngrams_edges_build12.png}
\caption{Intersection on the nGrams dataset, return edges.}
\label{fig:intersect}
\end{minipage}
\end{figure*}

{\bf Union and Intersection.}  \insql{union} and \insql{intersection}
by structure was evaluated by loading two time slices of the same
dataset with varying overlap.  The performance of the four conditions
depends on the size of the overlap (in the number of representative
graphs) and the evolution rate.  \ve produces the best performance
when the overlap is small (Figure~\ref{fig:union1}) and when the
evolution rate is high (Figure~\ref{fig:union2}), regardless of the
size of the overlap.  \og always produces good performance, flat
w.r.t. the overlap.  This makes sense, considering that in \og
\insql{union} and \insql{intersection} are implemented as joins (outer
or inner) on the vertices and edges of the two operands.  \ve, on the
other hand, splits the coalesced vertices/edges of each of the two
operands into intervals first, takes a union, and then reduces by key.
When the evolution rate is low and duration of an entity is high, such
as the case in the wikitalk dataset for vertices, the split produces a
lot of tuples to then reduce, and the performance suffers
(Figure~\ref{fig:union1}). \sg only produces good performance on
\insql{intersection} when few representative graphs overlap, and never
on \insql{union}. \hg performance is generally worse than \og, by a
constant amount in \insql{union}, and diverges in
\insql{intersection}.

\begin{figure*}[h]
\centering
\begin{minipage}{3.3in}
\centering
\includegraphics[width=2.8in]{figs/cc_wikitalk_build12.png}
\caption{Connected components on the wikitalk dataset.}
\label{fig:ccwiki}
\end{minipage}
\begin{minipage}{3.3in}
\centering
\includegraphics[width=2.8in]{figs/prank_twitter_build12.png}
\caption{Pagerank on the twitter dataset.}
\label{fig:pranktwitter}
\end{minipage}
\end{figure*}

{\bf Analytics.}  We implemented PageRank and Connected Components
analytics for the three graph-based representations using the Pregel
GraphX API.  PageRank was executed for 10 iterations or until
convergence, whichever came first.  Connected components was executed
until convergence with no limit on the number of iterations.
Performance of Pregel-based algorithms depends heavily on the
partition strategy, with best results achieved where cross-partition
communication is small.  For this reason, we evaluated only with the
E2D strategy.  

The performance was evaluated on time slices of varying size.  For a
very small number of RGs (1-2), \sg provides good performance.
However, \sg performance slows down linearly with the number of RGs.
\hg provides the best performance on analytics under most conditions,
with a linear increase with a significantly slower rate of growth.
The tradeoff between \og and \hg depends on graph evolution
characteristics.  If the graph is a growth-only evolution (such as in
our twitter dataset), \og is not denser than \hg and computes
everything in a single batch mode, which leads to the fastest
performance, as can be seen in Figure~\ref{fig:pranktwitter}.  If the
edge evolution represents more ephemeral connections that can come and
go, then \hg is less dense and scales better
(Figure~\ref{fig:ccwiki}).  Note that \og and \hg performance could be
further improved by computing them over coalesced structure-only V and
E, ignoring attributes.

{\bf Cluster Size.}  We next examine how the system implementation
scales with the the size of the cluster.  We evaluate the performance
of the following query:

\begin{small}
\begin{verbatim}
   slice
   aggregate(1 year, exists, exists)
   connected components
   materialize vertices
\end{verbatim}
\end{small}

This query, executed on the wikitalk dataset, computes connected
components over the past 10 years on the yearly scale.  Over the
twitter dataset the slice size is 5 years.

%%\begin{small}
%%\begin{verbatim}
%%Q2. UKDELIS
%%
%%   aggregate(3 months, exists, always)
%%   pagerank(20 iterations)
%%   project pagerank score
%%   aggregate(12 months, exists, exists, trend)
%%   get top 10
%%\end{verbatim}
%%\end{small}
\eat{
This query, executed on DELIS dataset, computes stable links between
websites, i.e. links that persist for 3 months, and uses them to
compute pagerank for each.  The score is projected and its trend
computed in an aggregation over the whole dataset time period (1
year).  The top 10 websites with the highest increase in pagerank are
returned.
}

For each operation, the best performing representation was selected
based on our experimental results.  Slice, project, and aggregate were
performed with \ve, analytics with \hg.  The results are in
Table~\ref{tab:clustersize}.  With the small wikitalk dataset,
performance improves initially with larger cluster sizes but levels
off at the largest size.  With the large twitter dataset, ...

\begin{table}
\caption{Effect of cluster size.}
\small
\begin{tabular}{| c | c | r |}
\hline
\multicolumn{1}{|c|}{\bfseries Cluster Size} & \multicolumn{1}{c|}{\bfseries wikitalk (min)} & \multicolumn{1}{r|}{\bfseries twitter} \\ \hline
2 & 15.21 & ? \\ \hline
4 & 9.35 & ? \\ \hline
8 & 6.55 & ? \\ \hline
12 & 5.05 & ? \\ \hline
16 & 4.84 & ? \\ \hline
\end{tabular}
\label{tab:clustersize}
\end{table}
