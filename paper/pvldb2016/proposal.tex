\documentclass[11pt]{article}
\usepackage{url}
\usepackage{xspace}
\usepackage{mdwlist}
\usepackage[left=2cm,top=1.5cm,right=2cm,bottom=1.5cm,nohead,nofoot]{geometry}

\newcommand\eat[1]{}
\newcommand\reminder[1]{*** #1 ***}
\newcommand*{\tg}{TGraph\xspace}

\eat{
\topmargin      0.0in
\headheight     0.0in
\headsep        0.0in
\oddsidemargin  0.0in
\evensidemargin 0.0in
\textheight     9.0in
\textwidth      6.5in
}

\pagestyle{empty}

\begin{document}

\begin{center}
{\Large\bf Analyzing Evolving Graphs}\\[7pt]

{\bf PI: Julia Stoyanovich} \\
College of Computing and Informatics \\
Drexel University \\
3141 Chestnut Street, Philadelphia PA, 19104, USA \\
stoyanovich@drexel.edu / (917) 470-8199 
\end{center}

\noindent{\bf Google Contacts.}  Cong Yu, Evgeniy Gabrilovich. 

\vspace{-0.4cm}
\subsection*{Abstract}
\vspace{-0.2cm}

Graphs are used to represent a plethora of phenomena, from the Web and
social networks, to biological pathways, to semantic knowledge bases.
Arguably the most interesting and important questions one can ask
about graphs have to do with their evolution. Which Web pages are
showing an increasing popularity trend?  How does influence propagate
in social networks?  How does knowledge evolve?

Much research and engineering effort today goes into developing
sophisticated graph analytics and their efficient implementations,
both stand-alone and in scope of data processing platforms.  Yet,
systematic support for scalable analytics over evolving graphs still
lacks.  In this project, we propose to develop a distributed framework
that fills this gap.  Our framework will support efficient computation
of {\em snapshot analytics}, which are executed on each graph in a
series of temporally-adjacent snapshots.  It will also support a rich
class of {\em trend analytics}, which are computed across groups of
temporally-adjacent snapshots.

Our framework will extend a popular open-source distributed data
processing engine.  All outcomes of this project, including code, data
and benchmarking methodologies, will be available in the open source.

\vspace{-0.2cm}
\subsection*{Research Goals}
\vspace{-0.2cm}

{\bf Motivation.}  The importance of networks cannot be
overstated. Networks arise in a plethora of domains, and are central
to many applications, both commercial and scientific.  Networks are
represented by graphs, and considerable research and engineering
effort is being devoted to developing effective and efficient graph
representations and analytics.  This is particularly important as
networks of interest are becoming ever larger, and as analytics are
becoming more sophisticated.

Arguably the most interesting and important questions one can ask
about networks have to do with their evolution, rather than with their
static state.  Let us consider a few examples of such questions.

{\em Which network nodes are showing an increasing popularity trend,
  or have increasing influence, and which are on a downward spiral?}
On the Web graph this information can help prioritize crawling.  In
social networks, it can be used for content recommendation and
advertisement targeting.  In semantic knowledge bases such as the
Google Knowledge Graph, this information can be used to capture the
dynamics of zeitgeist.  Here, node popularity can be quantified in a
number of ways including, for example, node degree, centrality or
PageRank score.

{\em Have any changes in network connectivity been observed, either
  suddenly or gradually over time?}  For networks describing
insulin-based metabolism pathways, gradual pathway disruption can be
used to determine the onset of type-2 diabetes.  For a website
accessibility network, sudden loss of connectivity can signal that
censorship is taking place, e.g., in response to a recent election or
another exogenous event.  In a co-authorship network, increasing
connectivity among topical communities indicates stronger
collaboration across domains.\eat{ Here, again, one may consider
  several ways of quantifying distance between nodes, including, e.g.,
  pair-wise distance, length of shortest path between communities, and
  graph density.}

As of late, efficient graph abstractions and analytics for {\em static
  graphs} have become available in scope of open source platforms such
as Apache Spark (through the GraphX API) and GraphLab (through the
PowerGraph library).  This in turn makes sophisticated graph analysis
methods available and accessible to researchers and practitioners,
facilitating their widespread adoption.  Further, because these
systems are open source, this encourages development and dissemination
of new graph analysis methods, and of more efficient implementations
of existing methods.

Beyond static graphs, analysis of {\em evolving graphs} has likewise
been receiving increasing attention, with most progress taking place
in the last decade, see~\cite{DBLP:journals/csur/AggarwalS14} for a
recent survey of the relevant data mining literature.  Yet, {\bf
  systematic support for scalable analytics over evolving graphs still
  lacks}.  This support is urgently needed, due first and foremost to
the scalability and efficiency challenges inherent in evolving graph
analysis, but also to considerations of usability and ease of
dissemination.  {\bf In this project, we propose to develop an
  open-source distributed framework that fills this gap}.  

{\bf Problem statement.} Our goal is to develop a scalable, usable and
extensible framework for analysis of evolving graphs.  Our framework
will support efficient computation of {\em snapshot analytics}, which
are executed on each graph in a series of temporally-adjacent
snapshots.  For example, we will efficiently compute the PageRank
score of nodes in multiple consecutive snapshots of the Web graph.
Our framework will support a rich class of {\em trend analytics},
computed across groups of temporally-adjacent snapshots.  For example,
we will efficiently compute the set of nodes that are showing an
increasing PageRank trend.

\vspace{-0.2cm}
\subsection*{Proposed Technical Approach and Outcomes}
\vspace{-0.2cm}

Proposed work will make part of our ongoing ambitious project on
declarative querying and analysis of evolving graphs, called Portal.
We will build upon, and non-trivially extend, the graph processing
abstractions of Apache Spark, a popular open-source distributed data
processing engine, and specifically of
GraphX~\cite{DBLP:conf/osdi/GonzalezXDCFS14}.  Our primary
contributions will be in the form of novel data structures and
performance optimizations, e.g., partitioning strategies, that
leverage structural and temporal locality to achieve
scalability. Preliminary results indicate that significant scalability
gains can be achieved with these techniques and with careful
engineering.

Our work shares motivation with recent work by Miao et
al.~\cite{DBLP:journals/tos/MiaoHLWYZPCC15}, who developed an
in-memory execution engine for temporal graph analytics.  Unlike Miao
et al., who focus on in-memory layout and locality-aware scheduling
mechanisms, we work in a distributed storage and processing
environment.  A further difference is that our work is in scope of
Apache Spark, a widely-used open source platform, while the work of
Miao et al. is on a proprietary stand-alone prototype.

{\bf TGraphs.} Our basic data structure is a temporal graph, or a {\em
  \tg} for short, which associates a sequence of graph snapshots $G_1
\ldots G_n$ with a sequence of consecutive non-overlapping time
periods of the same duration $p_1 \ldots p_n$.\eat{ Following the
  SQL:2011 standard, we adopt the closed-open period model, where a
  period represents all times starting from and including the start
  time, continuing to but excluding the end time.}

A snapshot graph (or a {\em snapshot} for short) is a pair $G =
(V,E)$, where $V$ is a finite set of nodes with schema
$(\underline{vid}, a_1, \ldots, a_n)$, and $E$ is a finite set of
edges connecting pairs of nodes from $V$, with schema
$(\underline{vid_1}, \underline{vid_2}, a_1, \ldots, a_m)$.
Attributes of vertices and of edges are not restricted to be of atomic
types, but may, e.g., be maps or tuples. However it is required that
all vertices (resp. edges) of $G$ have the same schema, i.e., $V$ and
$E$ are homogeneous sets.  Further, we require that all snapshots of a
particular \tg have the same vertex and edge schemas.
%
Importantly, vertex and edge identities persist across snapshots.
That is, if a vertex with the same $vid$ is present in multiple
snapshots, it refers to the same vertex.

{\bf TGraph analytics.} We will support two classes of \tg analytics.
The first, which we term {\em snapshot analytics}, refers to the
computation of the value of a function for each vertex, in each
snapshot of a \tg.  We will initially restrict our attention to
commutative associative functions in the ``think like a vertex''
family, but may extend the class of supported functions in later
stages of the project.  To optimize performance, we may additionally
differentiate between functions whose value can be computed by looking
at a fixed small neighborhood of a vertex (e.g., vertex degree, or the
number of neighbors at distance at most $k$, for a given small $k$),
and functions whose value potentially depends on the entire graph
(e.g., PageRank).  The challenge is to compute snapshot analytics with
resources (time / number of cluster nodes) sub-linear in the number of
snapshots.

Analytics in the second class, {\em trend analytics}, compute trends
in vertex attribute values, and optionally return a subset of the
vertices, selected with trend-based criteria.  Attribute values may be
given (e.g., a person's salary), or they may themselves be computed
(e.g., the number of a person's friends, computed with a snapshot
analytic).  An example is to return the top-$k$ vertices that show the
highest increase in PageRank values across snapshots of a \tg, for a
given small $k$.  Trend analytics will leverage the implementation of
snapshot analytics, with any performance optimizations.  Additionally,
we will investigate whether early termination criteria can be
developed, further optimizing the time / number of cluster nodes
needed to compute the result.

{\bf Physical representation.}  \tg is a logical data structure.  We
plan to experiment with several physical representations, which will
differ primarily on the kind of locality that they prioritize.  With
{\em structural locality}, neighboring vertices of the same snapshot
are laid out together, while with {\em temporal locality}, consecutive
states of the same vertex are laid out together.  A representation in
which each snapshot is stored explicitly naturally preserves
structural locality, but temporal locality is lost.  An alternative is
to store all vertices and edges of an evolving graph in a single data
structure, and to annotate each each vertex (resp. edge) with time
period information.  This representation emphasizes temporal locality,
while to some extent preserving structural locality.  We will also
design custom partitioning strategies, which will balance between
temporal and structural locality at operation evaluation time.

Which physical representation performs best will depend on several
factors, including (1) how time periods are represented, (2) how many
snapshots a \tg contains compared to the size of an individual
snapshot (i.e., whether snapshot size or evolution rate dominate), (3)
access patterns of a particular analytic operation, (4) what
partitioning strategies are used, and (5) to what extent different
physical representations are able to leverage lazy evaluation
available in Apache Spark.

{\bf Data and evaluation methods.}  We will evaluate performance of
our framework on a variety of real datasets.  We currently have 3 open
source datasets at our disposal.  (1) DBLP
({\url{dblp.uni-trier.de/xml}) contains co-authorship information from
  1936 through 2015, with over 1.5 million author nodes and over 6
  million undirected co-authorship edges.  (2) nGrams
  (\url{storage.googleapis.com/books/ngrams/books/datasetsv2.html})
  contains word co-occurrence information from 1520 through 2008, with
  over 1.5 million word nodes and over 65 million undirected
  co-occurrence edges. (3) DELIS
  (\url{law.di.unimi.it/webdata/uk-union-2006-06-2007-05}) contains
  monthly snapshots, from 05/2006 through 05/2007, of a portion of the
  Web graph focusing on the .uk domains, with a total of over 133
  million nodes and over 5.5 billion directed edges~\cite{BSVLTAG}.
  {\em Our work would greatly benefit from access to an evolving
    knowledge graph dataset, such as the Google Knowledge Graph, or a
    portion thereof.}

Our evaluation will focus on efficiency of implementation.  We will
carry out experiments on a 16-node in-house Hadoop cluster, and will
use external cloud computing platforms for larger scale
experimentation if the need arises.  The goal of our evaluation will
be to understand the relative performance of different data structures
and partitioning methods, for different analytic operations.

{\bf Outcomes.} The primary goal of this project is to develop a
framework for efficient computation of evolving graph analytics.  Our
secondary objective is to develop a class of analytics appropriate for
evolving semantic knowledge bases such as the Google Knowledge
Graph. As our starting point we will consider the applicability of
traditional measures of popularity and centrality, and of their
trends, to knowledge evolution and aging.  Further, we hope to have an
opportunity to work together with the Google Knowledge Graph team to
develop custom analytics for this domain.

\vspace{+0.2cm} {\bf Data policy.}  All outcomes of this project,
including code, data and benchmarking methodologies, will be available
in the open source.  The project website will become the central point
of dissemination of results, and will prominently list links to
downloadable datasets, and to code, which will be available on GitHub.
We will make an effort to offer our code as part of the Apache Spark
code base.

\vspace{+0.2cm} {\bf Budget.} The PI is requesting an award in the
amount of \$57,456: \$55,956 towards tuition and stipend for 1 PhD
student for 1 year, and \$1,500 towards conference travel for the PhD
student.

\vspace{+0.2cm} {\bf Results from past projects} In 2012 Prof. Susan
Davidson and I received a Google Research Award ``Identifying ranked
agreement among raters'', in the amount of \$10,000.  This funding was
used to initiate, with the help of an undergraduate student, a data
collection and analysis effort.  This work resulted in a
publication~\cite{DBLP:conf/cidr/StoyanovichADJM13} and laid a
foundation for my ongoing project ``Managing Preference Data''
(\url{db4pref.com}).

\bibliographystyle{abbrv}
\begin{small}
\bibliography{google}
\end{small}

\end{document}


