\section{System}
\label{sec:sys}

\begin{figure}[t!]
\begin{center}
\includegraphics[height=1.4in]{figs/architecture.pdf}
\caption{\ql system architecture.}
\vspace{-0.5cm}
\label{fig:arch}
\vspace{-0.2cm}
\end{center}
\end{figure}

The \ql system builds on GraphX~\cite{DBLP:conf/osdi/GonzalezXDCFS14},
an Apache Spark library, as depicted in Figure~\ref{fig:arch}.  Green
boxes indicate built-in components, while blue are those we added for
\ql.  We selected Apache Spark because it is a popular open-source
system, and because of its in-memory processing approach.  All
language operators on \tgs are available through the public API of the
\ql library, and may be used like any other library in an Apache Spark
application.

{\bf Query evaluation.}  \ql query execution follows the traditional
query processing steps: parsing, logical plan generation and
verification, and physical plan generation.  \ql re-uses and extends
SparkSQL abstractions for these steps.  A \ql query is rewritten into
a sequence of operators, and some operators are reordered to improve
performance.  For example, pushing temporal aggregation before
temporal join can sometimes lead to better performance.  A temporal
join query may be rewritten to include additional temporal selection
conditions, based on information about the temporal schema of the \tgs
being joined, which in turn significantly reduces data load time.

We developed several different physical representations and
partitioning strategies that are selected at the physical plan
generation stage.  These are described in Section~\ref{sec:physical}.
The \tgs are read from the distributed file system HDFS and processed
by Spark Workers, with the tasks assigned and managed by the runtime.
The System Catalog contains information about each data set, including
the temporal and structural schema, and temporal bounds.

{\bf Integration with SQL.} The \ql system
includes an interactive shell for exploratory data analysis.  Shell
users can define (materialized) \tg views, inspect query execution
plans and execute SQL queries with an embedded \ql view.  Consider
query \insql{Q3}, a SQL query that returns \insql{vid} and \insql{tr}
values of 20 vertices with the most significantly increasing
\insql{pagerank} trend.

\eat{
\begin{enumerate}[leftmargin=*]
\item
 Define (materialized) views of \tg using standard SQL
  \insql{create view} command.
\item View optimized execution plans for defined views using
  \insql{describe} command.
\item View results of queries using SQL, with \ql queries either
  embedded in SQL, or a previously defined view.
\item View defined views and functions.
\end{enumerate}
}
%{\bf Integration with SQL.}  

\begin{small}
\begin{verbatim}
Q3:   Select   VF.vid, VF.tr  
      From     T5.toVerticesFlat() as VF
      Order by tr
      Limit    20
\end{verbatim}
\end{small}

An important part of \insql{Q3} is the use of
\insql{T5.toVerticesFlat()} in the \insql{From} clause.  This is an
operation provided by the \ql framework, which collects all vertices
in the union of snapshots of \insql{T5} into a single nested vertex
collection and flattens it into \insql{VF} (\underline{vid}:int,
\underline{start}:date, \underline{end}:date, tr:float, mx:float).
\insql{VF} can be used in SQL queries.  \ql also provides an operation
that returns a flattened collection of edges, called
\insql{toEdgesFlat()}.

