For each slave:

1. Create instance.
  Go to https://cloud.cci.drexel.edu/dashboard
  Click on Instances.
  Click Launch Instance.
  Follow on-screen instructions. Pick unique name, like Slave05 if there are so far 4 slaves already created. Select the desired flavor - all slaves right now are 02c-08m-20d, which means 2 cores, 8G of RAM, 20G hard drive volume, separately attached. From the Boot Source drop-down, pick Boot from image (creates a new volume). Select Ubuntu Server 14.04 (2.2 GB) Image name. Click Delete on Terminate on. Add the local network dbgroup. Select root_waltz ssh key. If the key is not there, retrieve the public key from waltz - or ask Vera or Gaylord. When all configured, click Launch.
  Click on Volumes.
  Click Create Volume.
  Follow on-screen instructions. Pick corresponding name, like Slave05Hadoop. Set size. Current HDFS volumes are 200G each - this can grow in the future. Pick nova availability zone. Leave the other options with default values. Click Create Volume.
  Once the volume is in the list, click Edit Attachments for the volume through the drop-down on the right. Select the newly created instance. Click Attach Volume.

2. Basic configuration setup.
  Log in to waltz. Edit /etc/hosts file and add the new slave. 
  Copy the root key to the slave: 
    sudo scp updateRootAuthorizedKeys ubuntu@slave08:/home/ubuntu/
    sudo ssh ubuntu@slave08 "sudo bash updateRootAuthorizedKeys"
  Copy the /etc/hosts to all the cluster machines: (todo: simplify using ansible)
    sudo scp /etc/hosts root@master:/etc/hosts
    sudo scp /etc/hosts root@slave01:/etc/hosts
    ....
    sudo scp /etc/hosts root@slave08:/etc/hosts
  sudo ssh root@<slaveip>.
  Label the attached hdfs volume with a slave#hadoop label: mkfs -L slave08hadoop /dev/vdb - verify first that it is /dev/vdb which is not guaranteed.
  Edit /etc/fstab to automount /opt on the label created on the previous line. For example, if the label added above is slave03hadoop, then run: 
      echo "LABEL=slave03hadoop /opt ext2 defaults 0 2" | tee -a /etc/fstab
  Disable ipv6:
      echo "#disable ipv6" | tee -a /etc/sysctl.conf
      echo "net.ipv6.conf.all.disable_ipv6 = 1" | tee -a /etc/sysctl.conf
      echo "net.ipv6.conf.default.disable_ipv6 = 1" | tee -a /etc/sysctl.conf
      echo "net.ipv6.conf.lo.disable_ipv6 = 1" | tee -a /etc/sysctl.conf
  Restart sysctl: sysctl -p
  Test that ipv6 is off: cat /proc/sys/net/ipv6/conf/all/disable_ipv6  . If value is 1, it's good. If that doesn't work, reboot and recheck.

3. Upgrade the kernel 
  aptitude update
  aptitude full-upgrade
  set the correct time (US Eastern): sudo dpkg-reconfigure tzdata
  reboot

4. Setup Hadoop group and user
  sudo ssh root@<slaveip>
  addgroup hadoop
  adduser --ingroup hadoop hduser     (dbgroup is the hduser password on all current slaves for ease of maintenance)
  adduser hduser sudo
  Switch to hduser:
  su - hduser

5. SSH setup (as hduser)
  Copy master's ssh keys and configuration: (replace slave08 with ip)
       sudo scp -3 root@master:/home/hduser/.ssh/id_rsa.pub root@slave08:/home/hduser/.ssh/id_rsa.pub
       sudo scp -3 root@master:/home/hduser/.ssh/id_rsa root@slave08:/home/hduser/.ssh/id_rsa
       sudo scp -3 root@master:/home/hduser/.ssh/authorized_keys root@slave08:/home/hduser/.ssh/authorized_keys
       sudo ssh root@slave08
       chown hduser ~hduser/.ssh/id_rsa*
       chown hduser ~hduser/.ssh/authorized_keys
       chgrp hadoop ~hduser/.ssh/id*
       chgrp hadoop ~hduser/.ssh/authorized_keys 
  Test by logging in from this slave to each machine as hduser: ssh master, etc. Also test ssh <slave> from master and previous slaves.

6. Install/setup Java 7
  If you are on waltz:
  sudo ssh root@<slaveip>
  add-apt-repository ppa:webupd8team/java
  aptitude update
  aptitude install oracle-java7-installer

  su - hduser
  export JAVA_HOME=/usr/lib/jvm/java-7-oracle/
  echo "" | tee -a $HOME/.bashrc
  echo "export JAVA_HOME=/usr/lib/jvm/java-7-oracle/" | tee -a $HOME/.bashrc
  check that java is good: java -version

7. Install/Configure Hadoop
  cd /opt/
  sudo wget http://supergsego.com/apache/hadoop/core/stable/hadoop-2.6.0.tar.gz
  sudo tar xzf hadoop-2.6.0.tar.gz
  sudo mv hadoop-2.6.0 hadoop
  sudo chown -R hduser:hadoop hadoop
  sudo rm hadoop-2.6.0.tar.gz
  as hduser:
  echo "export HADOOP_HOME=/opt/hadoop" | sudo tee -a $HOME/.bashrc
  echo "export HADOOP_PREFIX=$HADOOP_HOME" | sudo tee -a $HOME/.bashrc
  echo "" | sudo tee -a $HOME/.bashrc
  echo "unalias fs &> /dev/null" | sudo tee -a $HOME/.bashrc
  echo "alias fs='hadoop fs'" | sudo tee -a $HOME/.bashrc
  echo "unalias hls &> /dev/null" | sudo tee -a $HOME/.bashrc
  echo "alias hls='fs -ls'" | sudo tee -a $HOME/.bashrc
  export HADOOP_HOME=/opt/hadoop
  echo "export PATH=$PATH:$HADOOP_HOME/bin" | sudo tee -a $HOME/.bashrc
  mkdir /opt/hadoop/tmp
  let's check it all worked:
    source ~/.bashrc
    which hadoop
    hadoop version
    hls
  Update configuration files: (slave06 has the right configuration, don't change the ip here)
    scp hduser@slave06:/opt/hadoop/etc/hadoop/core-site.xml /opt/hadoop/etc/hadoop/core-site.xml 
    scp hduser@slave06:/opt/hadoop/etc/hadoop/hadoop-env.sh /opt/hadoop/etc/hadoop/hadoop-env.sh
    scp hduser@slave06:/opt/hadoop/etc/hadoop/hdfs-site.xml /opt/hadoop/etc/hadoop/hdfs-site.xml 
    scp hduser@slave06:/opt/hadoop/etc/hadoop/mapred-site.xml /opt/hadoop/etc/hadoop/mapred-site.xml
    scp hduser@slave06:/opt/hadoop/etc/hadoop/yarn-site.xml /opt/hadoop/etc/hadoop/yarn-site.xml 
  For this command, replace slave08 with the name of the slave
  echo "slave08" | tee /opt/hadoop/etc/hadoop/slaves

  Test the configuration on the slave: hadoop fs -ls hdfs://master:9000/data
  Add new slave to master configuration:
    ssh hduser@master 'echo "slave08" | tee -a /opt/hadoop/etc/hadoop/slaves'

  export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop/
  Start the new slave hdfs data node on slave: $HADOOP_HOME/sbin/hadoop-daemon.sh --config "$HADOOP_CONF_DIR" --script "$bin/hdfs" start datanode
  Test: 
    hdfs dfsadmin -report  if the new slave shows up in the list with the expected capacity (just under 200GB), it's working.
  Note: to rebalance the disk utilization between data notes, run: hdfs balancer (it will take a long time).

8. Install/setup Mesos
  sudo apt-key adv --keyserver keyserver.ubuntu.com --recv E56151BF
  DISTRO=$(lsb_release -is | tr '[:upper:]' '[:lower:]')
  CODENAME=$(lsb_release -cs)
  echo "deb http://repos.mesosphere.io/${DISTRO} ${CODENAME} main" | sudo tee /etc/apt/sources.list.d/mesosphere.list
  sudo apt-get -y update
  sudo apt-get -y install mesos
  sudo service zookeeper stop
  sudo sh -c "echo manual > /etc/init/zookeeper.override"
  echo "zk://master:2181/mesos" | sudo tee /etc/mesos/zk
  sudo service mesos-master stop
  sudo sh -c "echo manual > /etc/init/mesos-master.override"
  echo "HADOOP_HOME=/opt/hadoop" | sudo tee -a /etc/default/mesos-slave
  sudo touch /etc/mesos-slave/?no-switch_user
     Yes, you want the question mark in the name of the file. It's what mesos expects.
  sudo sh -c "echo /opt/hadoop > /etc/mesos-slave/hadoop_home"
  sudo service mesos-slave restart
  Test if it's working:
    MASTER=$(mesos-resolve `cat /etc/mesos/zk`)
    mesos-execute --master=$MASTER --name="cluster-test" --command="sleep 5"  
    If you see task finish, you are good.


DONE!
------------------
Sources:
http://dogdogfish.com/2014/04/22/hadoop-from-spare-change/
http://dogdogfish.com/2014/04/26/installing-hadoop-2-4-on-ubuntu-14-04/
http://www.bogotobogo.com/Hadoop/BigData_hadoop_Install_on_ubuntu_single_node_cluster.php
https://docs.mesosphere.com/getting-started/datacenter/install/
https://strat0sphere.wordpress.com/2014/10/30/spark-on-mesos-installation-guide/
